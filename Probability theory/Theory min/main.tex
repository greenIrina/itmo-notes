\documentclass{article}
\usepackage[utf8]{inputenc} 
\usepackage[russian]{babel} 
\usepackage{amsmath} 
\usepackage{hyperref} 
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{wrapfig}
\usepackage{bbm}
\usepackage{parskip}
\usepackage{gensymb}
\usepackage{multicol}
\usepackage{array}
\usepackage{stackengine}
\usepackage{mathtools}
\usepackage[final]{pdfpages}
\parindent 0pt
\parskip 6pt
\newcommand{\numberset}[1]{\mathbb{#1}} 
\newcommand{\Aop}{\mathcal{A}}
\newcommand{\Bop}{\mathcal{B}}
\newcommand{\N}{\numberset{N}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Eps}{\mathcal{E}}
\newcommand{\Zero}{\mathbb{O}}
\newcommand{\Compl}{\mathbb{C}}
\newcommand{\n}{\bigbreak}
\usepackage[a4paper, total={6in, 8in}]{geometry}
\usepackage{color}
\usepackage{hyperref}
\def\letus{%
    \mathord{\setbox0=\hbox{$\exists$}%
             \hbox{\kern 0.125\wd0%
                   \vbox to \ht0{%
                      \hrule width 0.75\wd0%
                      \vfill%
                      \hrule width 0.75\wd0}%
                   \vrule height \ht0%
                   \kern 0.125\wd0}%
           }%
}
\DeclarePairedDelimiter\evaluat{.}{\rvert}
\reDeclarePairedDelimiterInnerWrapper\evaluat{nostar}{\mathopen{}#2\mathclose{#3}}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    urlcolor=blue,
    linktoc=all
}
\title{ТеорВер, 3 семестр, теормин}
\author{Ирина Ткаченко (:}
\begin{document}
\maketitle 
\tableofcontents
\newpage
\section{Аксиомы Колмогорова, аксиомы непрерывности, их связь}
\subsection{Аксиомы Колмогорова}
$(\Omega,\,\Sigma)$ -- измеримое пространство. Введём функцию $P\::\:\Sigma\,\to\,[0,\,1]$ такую, что
\begin{enumerate}
    \item \textit{\textbf{Аксиома I} (существование вероятности событий)}: $\forall\,A\in\Sigma\::\:P(A)\geq0$
    \item \textit{\textbf{Аксиома II} (нормировка вероятности)}: $P(\Omega)=1$
    \item \textit{\textbf{Аксиома III} (аддитивность вероятности)}: пусть $A$ --  счетный набор попарно дизъюнктных подмножеств, тогда $P(\sum\,A)=\sum\,P(A)$
\end{enumerate}
$P$ -- вероятностная мера, тройка $(\Omega,\Sigma,P)$ -- вероятностное пространство.
\subsection{Аксиомы непрерывности для системы множеств}
\subsubsection{Первая аксиома}
Пусть $(\Omega,\Sigma,P)$ -- вероятностное пространство. Выделено событие $B_1\supseteq B_2\supseteq \dots$ -- невозрастающая последовательность событий. $B_i\in\Sigma,\,\forall\,i=1,\dots,+\infty$
\[
B=\bigcup_{n=1}^{\infty} B_{n}=\lim_{n\to\infty}\,B_n,\:\:B\in\Sigma
\] 
$$ P(B)=P(\lim_{n\to\infty}\,B_n)=\lim_{n\to\infty}\,P(B_n) $$
\subsubsection{Вторая аксиома}
Пусть $(\Omega,\Sigma,P)$ -- вероятностное пространство. Выделено событие $A_1\subseteq A_2\subseteq \dots$ -- неубывающая последовательность событий. $A_i\in\Sigma,\,\forall\,i=1,\dots,+\infty$
$$ A=\bigcup_{n=1}^{\infty} A_{n}=\lim_{n\to\infty}\,A_n,\:\:A\in\Sigma $$
$$ P(A)=P(\lim_{n\to\infty}\,A_n)=\lim_{n\to\infty}\,P(A_n) $$
\subsubsection{Связь аксиом непрерывности}
Аксиомы непрерывности эквивалентны.
\subsection{Связь аксиом Колмогорова и аксиом непрерывности}
Аксиома счетной аддитивности ($3$-я аксиома Колмогорова) эквивалентна аксиоме конечной аддитивности плюс $1$ аксиома непрерывности.
\newpage
\section{Свойства вероятностной меры}
\begin{enumerate}
    \item $p(\varnothing)=0$
    \item \textit{Аксиомы конечной аддитивности}  Для любого конечного набора попарно несовместных событий $A_1,\dots,A_n\in\Sigma,\,A_i\cap A_j=\varnothing\,\forall i\neq j$ имеет место равенство:
    $$ P\Big(\sum^n_{i=1}A_i\Big)=P\Big(\bigcup^n_{i=1}A_i\Big)=\sum^n_{i=1}P(A_i) $$
    \item Для любого события $A$ выполнено: $P(\overline{A})=1-P(A)$
    \item Если $A\subseteq B$, то $P(B\setminus A)=P(B)-P(A)$
    \item Для любого события $A$ выполнено $0\leq P(A)\leq 1$
    \item Всегда $P(A\cap B)=P(A)+P(B)-P(A\cup B)$
\end{enumerate}
\newpage
\section{Дискретные схемы: классическая схема, геометрическая схема, схема Бернулли, схема Пуассона. Определение, моменты}
чет я уже устала(
\subsection{Дискретные схемы}
\textbf{Дискретная схема} -- частный случай общей. $\Omega$ -- не более чем счётно, $\Sigma$ -- $\sigma$-алгебра всех подмножеств $\Omega$.
\begin{enumerate}
    \item Для события $A$ верно: $$ \sum_{\omega\in A}p(\omega)\geq 0 $$
    \item Верно: $$ p(\Omega)=\sum_{\omega\in\Omega}p(\omega)=1 $$
    \item Если $A_1,\dots,A_n$ -- дизъюнктный набор подмножеств, то что-то непонятное
\end{enumerate}
\subsubsection{Классическая схема}
Пусть $|\Omega|=n$ и $\,\omega_1,\dots,\omega_n$ -- равновозможные, т.е. $p(\omega_i)=\cfrac{1}{n},\,p(A)=\cfrac{|A|}{|\Omega|}.$ 

$p(\Omega)=1$ -- всё верно.
\subsubsection{Геометрическая схема}
Параметр схемы $p\in(0;\,1)$. Пусть $A$ -- событие, $p=p(A)\in(0;\,1)$ и $A$ -- результат опыта с двумя исходами. Проводятся независимые испытания до первого поялвения $A$. $\Omega=\{\omega_1,\dots,\omega_n,\dots\}$, где $\omega_k=\overline{AA\dots}A$, то есть $A$ выпало на $k$-ом ходе. $p(\omega_k)=(1-p)^{k-1}p=q^{k-1}p$. Тогда $\sum p(\omega_k)=1$, как и должно быть.
\subsubsection{Схема Пуассона}
Параметр схемы $\lambda>0$. $\Omega=\{\omega_0,\dots,\omega_n,\dots\}$. Вероятностная мера (или вероятность?) $p(\omega_n)=\cfrac{\lambda^n}{n!}e^{-\lambda}$. Есть положительная определённость $$ \sum_{n=0}^{\infty}\cfrac{\lambda^n}{n!}e^{-\lambda}=e^{-\lambda}\sum_{n=0}^{\infty}\cfrac{\lambda^n}{n!}=e^{-\lambda}e^{\lambda}=1 $$

\subsubsection{Схема Бернулли повторения опыта}
Параметр схемы $n\geq0,\,p\in[0;\,1]$. $\Omega=\{\omega_1,\dots,\omega_n\},\,p(\omega)=p^{k(\omega)}q^{n-k(\omega)}$, где $k(\omega)$ -- число успехов в серии из $n$ испытаний. $\omega_n=B_{n,p}(m)=\sum\omega$ -- ровно $m$ успехов. $|B_{n,p}(m)|=C^n_m\cdot p(\omega_m)=C^n_m p^m q^{n-m}.$
$$ \sum p(\omega_m)=\sum_{m=0}^n C^n_m p^m q^{n-m}=(p+q)^n=1 $$
\subsection{Случайные величины, основные определения}
\textbf{Случайной} называют \textbf{величину}, которая в результате испытания примет одно и только одно числовое значение, зависящее от случайных факторов и заранее непредсказуемое.

Формальное математическое определение следующее: пусть $(\Omega,\Sigma,P)$ — вероятностное пространство, тогда случайной величиной называется функция $X\::\:\Omega\to\R$, измеримая относительно $\Sigma$ и борелевской $\sigma$-алгебры на $\R$. Другими словами, функция $X\::\:\Omega\to\R$ называется случайной величиной, если для любых вещественных чисел $a$ и $b$ множество событий $\omega$, таких что $X(\omega)\in(a,\,b)$, принадлежит $\Sigma$.

\textbf{Математическое ожидание} $EX$ -- мера среднего значения случайной величины, равная $EX=\sum X(\omega)\cdot p(\omega)$.

\textbf{Дисперсией} случайной величины называется математическое ожидание квадрата отклонения этой случайной величины от её математического ожидания $DX=E[[X-EX]^2]$ или $DX=E[X^2]-(EX)^2$.

\textbf{Среднее квадратичное отклонение} равняется корню из дисперсии.

\textbf{Ковариация} двух случайных величин равняется $$cov(X,Y)=\cfrac{D[X+Y]-DX-DY}{2}=E[XY]-EX\cdot EY$$
\subsection{Определение моментов}
Дана сулчайная величина $X$, определённая на некотором вероятностном пространстве.
\begin{enumerate}
    \item $k$-м \textbf{начальным} моментом случайной величины $X$ при $k\in\N$ называется\quad величина $\nu_k=E[X^k]$, если математическое ожидание $E[*]$ определено.
    \item $k$-м \textbf{центральным} моментом сл. в. $X$ называется величина $\mu_k=E[(X-EX)^k]$
    \item $k$-м \textbf{абсолютным} моментом сл. в. $X$ называется величина $\nu_k=E[|X|^k]$
    \item $k$-м \textbf{центральным абсолютным} моментом случайной величины $X$ называется величина $\mu_k=E[|X-EX|^k]$
    \item \textbf{\textit{НЕ НАДО}} $k$-м \textbf{факториальным} моментом $X$ называется величина $\mu_k=E[X(X-1)\dots (X-k+1)]$
\end{enumerate}
\newpage
\section{Функции распределения, плотности, моменты нормального, показательного, равномерного распределений}
\subsection{Функция распределения}
\subsubsection{Определение}
\textbf{Функция распределения} — функция, характеризующая распределение случайной величины или случайного вектора; вероятность того, что случайная величина $X$ примет значение, меньшее или равное $x$.
$$ F(t)=F_X(t)=P_X(X<t)=P_x((-\infty,\,t)) $$
\subsubsection{Свойства}
\begin{enumerate}
    \item $F_X(t)$ не убывает.
    \item $ \exists\,\lim\limits_{t\to\infty}F_X(t)=1 $ и $\exists\,\lim\limits_{t\to-\infty}F_X(t)=0$
    \item $F_X(t)$ непрерывна слева.
\end{enumerate}
\subsection{Плотность распределения}
\subsubsection{Определения}
$P_X=P_X(dx)$ \textbf{абсолютно непрерывна}, если $\exists\,f_X(x)\geq 0\:\forall\,A\in\Sigma\::\:P_X(A)=\int\limits_A f_X(x)dx$.

\textbf{Плотность распределения вероятностей} представляет собой производную функцию распределения: $f_X(x)=F_X'(x)$. $f_X(x)$ -- вероятность попадания случайной величины $X$ в отрезок $[x,\,x+\Delta x]$.

\subsubsection{Свойства}
Плотность распределения вероятностей:
\begin{enumerate}
    \item неотрицательна;
    \item интегрируема;
    \item нормирована: $\int\limits_{\R}f_X(x)dx=1$.
\end{enumerate}
\subsection{Виды распределений и их моменты}
\subsubsection{Нормальное распределение}
$$X \sim N(a,\,\sigma)$$
$ f_X(x)=\cfrac{1}{\sigma\sqrt{2\pi}}\cdot e^{-\frac{(x-a)^2}{2\sigma^2}} $, где $a,\,\sigma\in\R$ -- параметры.

$$F_X(x)=\cfrac{1}{\sigma\sqrt{2\pi}}\,\int_{-\infty}^x e^{-\frac{(x-a)^2}{2\sigma^2}}dt$$

\textbf{Стандартным нормальным распределением} называется нормальное распределение с параметром $a=0$ и стандартным отклонением $\sigma=1$.

\textbf{Математическое ожидание} $EX=a$, \textbf{дисперсия} $DX=\sigma^2$.

\textbf{Моменты}.

Если $X$ имеет нормальное распределение, то для неё существуют (конечные) моменты при всех $p$ с действительной частью больше $-1$. Для неотрицательных целых $p$, центральные моменты таковы:
$$ E[X^p]=\begin{cases}0\quad\quad\quad p=2n+1,\\ \sigma^p(p-1)!!\quad\quad p=2n.\end{cases} $$

Центральные абсолютные моменты для неотрицательных целых $p$ таковы:
$$ E[|X|^p]=\sigma^p(p-1)!!\cdot\begin{cases}\sqrt{\frac{2}{\pi}} \quad\quad p=2n+1,\\1\quad\quad p=2n.\end{cases} $$
\subsubsection{Показательное}
$Exp_{\lambda},\,\lambda>0$

$$f_X(x)=\begin{cases}\lambda e^{-\lambda x}\quad x>0,\\0\quad x\leq 0.\end{cases}$$

$$F_X(x)=\begin{cases}1- e^{-\lambda x}\quad x>0,\\0\quad x\leq 0.\end{cases}$$

Обладает Марковским свойством (при известном настоящем -- будущее не зависит от прошлого).

\textbf{Математическое ожидание} $EX=\cfrac{1}{\lambda}$, \textbf{дисперсия} $DX=\cfrac{1}{\lambda^2}$, \textbf{моменты} $E[X^n]=\cfrac{n!}{\lambda^n}$.

\subsubsection{Равномерное}
$X\sim U(a,\,b)$
$$ f_X(x)=\begin{cases}
\cfrac{1}{b-a}\quad\quad x\in [a;\,b),\,b>a,\\
0\quad\quad x\notin[a;\,b)
\end{cases}$$
$$ F_X(x)=\begin{cases}
0 \quad\quad x\leq a,\\
\cfrac{x-a}{b-a}\quad\quad a<x\leq b,\\
1\quad\quad x\geq b
\end{cases} $$
\textbf{Математическое ожидание} $EX=\cfrac{a+b}{2}$, \textbf{дисперсия} $DX=\cfrac{(b-a)^2}{12}$, \textbf{моменты}:
$$ E[X^n]=\cfrac{1}{n+1}\sum_{k=0}^n a^k b^{n-k}=\cfrac{b^{n+1}-a^{n+1}}{(b-a)(n+1)} $$
\newpage
\section{Независимость событий и случайных величин. Необходимые и достаточные условия независимости дискретных и непрерывных случайных величин}
\subsection{Определения}
События называются независимыми, если $P(A \cap B) = P(A) \cdot P(B)$.

Cлучайные величины $X$ и $Y$ называются независимыми, если $\forall\,a,b\in\R$ события $(X\leq a)$
и $(Y\leq b)$ независимы.
$$ P((X\leq a)\cap(Y\leq b))=P(X\leq a)\cdot P(Y\leq b), $$
то есть, распеределительный закон одной не зависит от распределительного закона другой.

\subsection{Условия независимости}
\subsubsection{Дискретный случай}
Cлучайные величины $X$ и $Y$ независимы тогда и только тогда, когда имеет место $P_{ij}=P_{xi}\cdot P_{yj}$, где $P_{ij}$ -- вероятность случайного вектора $(X,Y)$, то есть $P_{ij}=P(\{\omega\::\:X(\omega)=xi\}\cap\{\omega\::\:Y(\omega)=yj\})$.
\subsubsection{Просто так}
Для того, чтобы случайные величины $X$ и $Y$ были независимы, необходимо и достаточно, чтобы функция распределения системы $(X,Y)$ была равна произведению функций распределения составляющи, то есть $F_{X,Y}(x,y)=F_X(x)\cdot F_Y(y)$.
\subsubsection{Непрерывный случай}
Для того, чтобы случайные величины $X$ и $Y$ Были независимы, необходимо и достаточно, чтобы плотность совместного распределения системы $(X,Y)$ была равна произведению плотностей распределения составляющих, то есть $f_{X,Y}(x,y)=f_X(x)\cdot f_Y(y)$.
\newpage
\section{Свойство отсутствия последействия и показательное распределение}
\subsection{Определение отсутствия последействия}
Случайная величина обладает свойством отсутствия последствия (\textit{Марковское}), если:
\begin{enumerate}
    \item $P(x\geq0)=1$
    \item$P(X>x)>0\:\forall\,x>0$
    \item $P(X>x+y\,|\,x>y)=P(X>x)\:\forall\,x,y>0$
\end{enumerate}
Свойством отсутствия последствия обладает только показательное распределение.

\subsection{Показательное распределение}
$Exp_{\lambda},\,\lambda>0$

$$f_X(x)=\begin{cases}\lambda e^{-\lambda x}\quad x>0,\\0\quad x\leq 0.\end{cases}$$

$$F_X(x)=\begin{cases}1- e^{-\lambda x}\quad x>0,\\0\quad x\leq 0.\end{cases}$$
\newpage
\section{Понятие условной вероятности, условное распределение}
\subsection{Условная вероятность}
\subsubsection{Определение}
Пусть задано вероятностное пространство $(\Omega,P)$. \textbf{Условной вероятностью} события $A$ при условии, что произошло событие $B$, называется число $P(A\,|\,B)=\cfrac{P(A\cap B)}{P(B)}$, где $A$ и $B\subset\Omega$.
\subsubsection{Формула Байеса}
Формула Байеса вытекает из определения условной вероятности. Вероятность совместного события $AB$ выражается через условные вероятности: $P(AB)=P(A\,|\,B)P(B)=P(B\,|\,A)P(A)$. Следовательно, 
$$ P(A\,|\,B)=\cfrac{P(AB)}{P(B)}=\cfrac{P(B\,|\,A)P(A)}{P(B)} $$
\subsubsection{Случай с несовместными гипотезами}
Вероятность события $B$ выражается (если $A$ -- подмножество объединений гипотез $H_i$) как $$ P(B)=\sum_{i=1}^n P(A_i)\cdot P(B\,|\,A_i)$$
Формула Байеса
$$ P(A_j\,|\,B)=\cfrac{P(A_j)\cdot P(B\,|\,A_j)}{\sum_{i=1}^n P(A_i)\cdot P(B\,|\,A_i)}  $$
\subsection{Условное распределение}
\subsubsection{Определение}
\textbf{Условное распределение} -- распределение случайной величины при условии, что другая случайная величина принимает определённое значение.

Пусть задано вероятностное прострнаство $(\Omega,\Sigma,P)$.
\subsubsection{Дискретные случайные величины}
Пусть $X$ и $Y$ -- случайные величины, такие что случайный вектор $(X,Y)^T$ имеет дискретное распределение, задаваемое функцией вероятности $p_{X,Y}(x,y)$. Пусть $y_0\in\R$ такой, что $P(Y=y_0)>0$, тогда функция
$$ p_{X\,|\,Y}(x\,|\,y_0)=P(X=x\,|\,Y=y_0)=\cfrac{p_{X,Y}(x,y_0)}{p_Y(y_0)} $$
где $p_y$ -- функция вероятности случайно величины $Y$, называется \textbf{условной функцией вероятности} случайно величины $X$ при условии, что $Y=y_0$. Распределение, задаваемое такой функцией, называется \textbf{условным распределением}.
\subsubsection{Абсолютно непрерывные случайные величины}
Пусть $X$ и $Y$ -- случайные величины, такие что случайный вектор $(X,Y)^T$ имеет абсолютно непрерывное распределение, задаваемое плотностью вероятности $f_{X,Y}(x,y)$. Пусть $y_0\in\R$ такой, что $f_Y(y_0)>0$, где $f_Y$ -- плотность случайной величины $Y$. Тогда функция
$$ f_{X\,|\,Y}(x\,|\,y_0)=\cfrac{f_{X,Y}(x,y_0)}{f_Y(y_0)} $$
называется \textbf{условной плотностью} вероятности случайной величины $X$ при условии, что $Y=y_0$. Распределение, задаваемое такой плотностью, называется \textbf{условным распределением}.
\newpage
\section{Функция регрессии. Геометрический смысл}
\subsection{Определение}
\subsubsection{Первое}
\textbf{Регрессия} — зависимость математического ожидания (например, среднего значения) случайной величины от одной или нескольких других случайных величин (свободных переменных), то есть $E[y\,|\,x]=f(x)$.

\textbf{\textit{НЕ НАДО}} \textbf{Регрессионным анализом}
называется поиск такой функции $f$, которая описывает эту зависимость. Регрессия может быть представлена в виде суммы неслучайной и случайной составляющих: $y=f(x)=\nu_1$, где $f$ -- функция регрессионной зависимости, а $\nu$ -- аддтивная случайная величина с нулевым матожиданием.

В отличие от чисто функциональной зависимости $y=f(x)$, когда каждому значению независимой переменной $x$ соответствует одно определённое значение величины $y$, при регрессионной связи одному и тому же значению $x$ могут соответствовать в зависимости от случая различные значения величины $y$.

\subsubsection{Второе (вроде более каноничное)}
$\letus \,(\Omega,\Sigma,P)$ -- дискретное вероятностное пространство, $X=X(\omega),\,Y=Y(\omega)$ -- случайные величины.

$\letus\, E[Y]<\infty,\,\letus\, x=x_1,x_2,\dots,\,\letus\,B_j=\{\omega\::\:X(\omega)=x_j\}=X^{-1}(x_j),\,\letus\,P(B_j)>0$.

$\letus\,T=\{B_j\}_j$ -- разбиение $\Omega$, $P_{x_j}=P(x=x_j)=P(B_j)$.

Функция $m(x)$ называется \textbf{функцией регрессии} случайной величины $Y$ на случайную величину $X$:
$$ m(x)=m_{Y\,|\,X}(x)=\begin{cases}
E[Y\,|\,\{\omega\::\:X(\omega)=x\}]\quad\quad P(X=x)\neq 0\\
0\quad\quad P(X=x)=0
\end{cases}$$

\subsection{Геометрический смысл}
?
\newpage
\section{Формула полного математического ожидания, её связь с формулой полной вероятности}
\subsection{Формула полного математического ожидания}
Пусть $T=\{A_x\}$ -- разбиение $\Omega$. Пусть $EX$ -- конечное, тогда справедлива формула
$$ EX=\sum_{k\::\:p(A_k)\neq 0} E[X\,|\,A_k]\cdot p(A_k) $$
\subsection{Связь с ФПВ}
Пусть $X=I_A$ -- индикаторная случайная величина, тогда $$p(A)=E[I_A]=\sum_{k\::\:p(A_k)\neq 0} E[I_A\,|\,A_k]\cdot p(A_k)=\sum_{k\::\:p(A_k)\neq 0} p(A\,|\,A_k)\cdot p(A_k)$$ То есть формула полной вероятности это частный случай формулы полного математического ожидания.
\newpage
\section{Условное математическое ожидание $E[Y\,|\,X]$. Геометрический смысл}
\subsection{Условное математическое ожидание}
\subsubsection{Определение}
Пусть $(\Omega,\Sigma,P)$ -- вероятностное простарнство, $X$ -- случайная величина. \textbf{Математическим ожиданием} случайной величины $X$ по множеству $B$ называется величина (если интеграл сходится абсолютно):
$$ E[X,B]=\int\limits_{B}X(\omega)p(d\omega) $$
Условным математическим ожиданием случайной величины $X$ относительно события $B\in\Sigma$ с вероятностью $p(B)\neq 0$ называется величина
$$ E[X\,|\,B]=\cfrac{E[X,B]}{p(B)} $$
\subsubsection{Определение для дискретных}
\textbf{Условным математическим ожиданием} дискретной случайной величины $Y$ при условии $X=x$ называется величина:
$$ E[Y\,|\,X=x]=\sum_{i=1}^n y_i\cdot p(y_i\,|\,x) $$
\subsubsection{Определение для непрерывных}
\textbf{Условным математическим ожиданием} непрерывной случайной величины $Y$ при условии $X=x$ называется величина:
$$ E[Y\,|\,X=x]=\int_{-\infty}^{\infty} y\cdot f(y\,|\,x)dy $$
где $f(y\,|\,x)$ -- условная плотность случайной величины $Y$ пи $X=x$.

\subsubsection{Интересная ссылка}
\href{https://eduardgorbunov.github.io/assets/files/Seminar07_675.pdf}{Why not}
\subsubsection{Теорема о разложении дисперсии}
$$ DY=D[E[Y\,|\,X]]+E[D[Y\,|\,X]] $$
\subsection{Геометрический смысл}
?
\newpage
\section{Линейная регрессия}
\subsection{Определение}
\textbf{Линейная регрессия} -- метод восстановления зависимости одной (объясняемой, зависимой) переменной от другой или нескольких других переменных (факторов, регрессоров, независимых переменных) с линейной функцией зависимости. Данный метод позволяет предсказывать значения зависимой переменной по значениям независимой переменной.

Линейная регрессия предполагает, что функция $f$ зависит от параметров $\omega$ линейно. При этом линейная зависимость от свободной переменной $x$ необязательна,
$$ y=f(\omega,x)+\nu=\sum_{j=1}^N \omega_j\cdot g_j(x)+\nu $$
\subsection{Другое определение))}
Пусть $L_x=\{ax+b\::\:a,b\in\R\}$ -- линейное пространство линейных функций от $x$. \textbf{Линейной регрессией} $Y$ на $X$ называется решение экстремальной задачи $$ inf_{g\in L_x} E[(Y-(ax+b))^2]=E[(Y-a^*x-b^*)^2] $$
То есть найти функцию $g(x)=a^* x+b^*$.
$$ a^*=\cfrac{cov(X,Y)}{DX} \quad\quad b^*=EY-a\cdot DX $$
\newpage
\section{Неравенство для моментов}
\subsection{Неравенство Шварца (все моменты $E$)}
\textit{мало ли понадобится}

$$ E[(XY)]\leq\sqrt{E[X^2]E[Y^2]} $$
\subsection{Неравенство Йенсена}
\subsubsection{Борелевская дичь}
\textbf{Борелевская сигма-алгебра} -- минимальная сигма-алгебра, содержащая все открытые подмножества топологического пространства (также она содержит и все замкнутые). Эти подмножества также называются борелевскими.

\textbf{Борелевская функция} -- отображение одного топологического пространства в другое (обычно оба суть пространства вещественных чисел), для которого прообраз любого борелевского множества есть борелевское множество.

\subsubsection{Формулировка}
Пусть $(\Omega,\Sigma,P)$ -- вероятностное пространство, $X$ -- случайная величина с конечным первым моментом, $\varphi\::\:\R\to\R$ -- выпуклая вниз борелевская функция. Тогда
$$ \varphi(EX)\leq E[\varphi(X)] $$
\subsection{Следствие из Йенсена (неравенство для моментов)}
Если $E[|X|^t]<\infty$, то для любого $s\in(0,\,t)$ выполняется
$$ \sqrt[s]{E[|X|^s]}\leq\sqrt[t]{E[|X|^t]} $$
\newpage
\section{Закон больших чисел}
\subsection{Слабый закон больших чисел}
Слабый закон больших чисел гласит, что среднее значение выборки сходится по вероятности к математическому ожиданию.
$$ \overline{X}_n\xrightarrow{P}\mu\quad n\to\infty $$
То есть $\forall\,\epsilon>0$:
$$ \lim_{n\to\infty} P(|\overline{X}_n-\mu|>\epsilon)=0 $$
Слабый закон утверждает, что для любых ненулевых указанных границ, независимо от того, насколько они малы, при достаточно большой выборке вероятность того, что среднее значение выборки будет близко к математическому ожиданию, очень высока в пределах этих границ.

\subsection{Усиленный закон больших чисел}
Последовательность ${ X_{1},X_{2},...}$ удовлетворяет усиленному закону больших чисел, если $\forall \epsilon >0$ вероятность одновременного выполнения всех неравенств $|\overline{X}_n-\mu_n|\leq\epsilon,\,|\overline{X}_{n+1}-\mu_{n+1}|\leq\epsilon,\dots$ стремится к $1$ при $n\to\infty$.

Таким образом, здесь рассматривается поведение всей последовательности сумм в целом, в то время как в обычном законе больших чисел речь идет лишь об отдельных суммах.

\subsection{Теорема Колмогорова}
Теорема Колмогорова для случайных величин с конечными дисперсиями утверждает, что из условия
$$ \sum_{n=1}^{\infty} \cfrac{D[X_n]}{n^2}<\infty $$
вытекает приложимость к последовательности $X_1,\,X_2,\dots$ усиленного закона больших чисел с $A_n=E[\overline{X}_n]$.
\newpage
\section{Центральная предельная теорема}
\subsection{Классическая центральная предельная теорема}

\end{document}
